#+TITLE: 1.2 Procedures and the Processes They Generate

Considering computing a factorial:

#+BEGIN_SRC scheme
(define (factorial n)
  (if (= n 1)
      1
      (* n (factorial (- n 1)))))
#+END_SRC

vs.

#+BEGIN_SRC scheme
(define (factorial n)
  (fact-iter 1 1 n))

(define (fact-iter product counter max-count)
  (if (> counter max-count)
      product
      (fact-iter (* counter product)
                 (+ counter 1)
                 max-count)))
#+END_SRC

The first is said to be a /linear recursive process/, since the interpreter must keep
track of an ever increased number /deferred operations/ in a chain.  Upon reaching the
bottom, the first if branch, operations are performed bubbling back up.

The second is said to be a /linear iterative process/. At any given time, the state of
the process can be summarized by a fixed number of /state variables/.  This is said to
be a /recursive procedure/ (or function) but *not* a /recursive process/!  

[Does a recursive process have an ever increasing call stack?]

Yes, Scheme and most Lisps offer tail-recursion whereby a recursive function is not
implemented as recursive process, which is expensive (memory, stack overflow).  C does
not offer tail-recursion and therefore looping constructs are required.

** Tree Recursion
Classic Fibonacci sequence.

#+BEGIN_SRC scheme
(define (fib n)
  (cond ((= n 0) 0)
        ((= n 1) 1)
        (else (+ (fib (- n 1))
                 (fib (- n 2))))))
#+END_SRC

Produces a tree-shaped process. It is time inefficient because each there are many
identical sub trees, and as many leaves as the integer return value of the
calculation.  It is space efficient because at any point the process the size of the
stack is only as big as the number of nodes above the current one.

Iteratively calculated Fibonacci sequence:

#+BEGIN_SRC scheme
(define (fib n)
  (fib-iter 1 0 n))

(define (fib-iter a b count)
  (if (= count 0)
      b
      (fib-iter (+ a b) a (- count 1))))
#+END_SRC

Counting change:

#+BEGIN_SRC scheme
(define (count-change amount)
  (cc amount 5))

(define (cc amount kinds-of-coins)
  (cond ((= amount 0) 1)
        ((or (< amount 0) (= kinds-of-coins 0)) 0)
        (else (+ (cc amount
                     (- kinds-of-coins 1))
                 (cc (- amount
                        (first-denomination kinds-of-coins))
                     kinds-of-coins)))))

(define (first-denomination kinds-of-coins)
  (cond ((= kinds-of-coins 1) 1)
        ((= kinds-of-coins 2) 5)
        ((= kinds-of-coins 3) 10)
        ((= kinds-of-coins 4) 25)
        ((= kinds-of-coins 5) 50)))
#+END_SRC

** Orders of Growth
Synonym for Big O notation.

*Exercise 1.14*
#+BEGIN_EXAMPLE
(cc 11 5)
 (cc -39 5) => 0
 (cc 11 4)
  (cc -14 4) => 0
  (11 3)
   (1 3)
    (-9 3) => 0
    (1 2)
      (-4 2) => 0
      (1 1)
        (0 1) => 1
        (1 0) => 0
  (11 2)
   (6 2)
    (1 2)
     (-4 2) => 0
     (1 1)
      (0 1) => 1
      (1 0) => 0
    (6 1)
     (5 1)
      (4 1)
       (3 1)
        (2 1)
         (1 1)
          (0 1) => 1
          (1 0) => 0
         (2 0) => 0
       (3 0) => 0
      (4 0) => 0
     (5 0) => 0
    (6 0) => 0
...
#+END_EXAMPLE

Space is constant but steps are exponential, I'm not sure of the factor.

*Exercise 1.15*
a) first /n/ such that x is < 0.1 for 
#+BEGIN_SRC scheme
(* 12.15 (expt 3 -n))
;; or
(ceiling (- (logb (/ 1 (* 10 12.15)) 3)))
#+END_SRC

b) space is time are equivalent, and can be expressed as
#+BEGIN_SRC scheme
(ceiling (- (logb (/ 1 (* 10 a)) 3)))
#+END_SRC
Or simply O(log n)

** Exponentiation
** Greatest Common Divisors
Interesting note which clears something up for me, particularly the difference between
~modulo~ and ~remainder~ (from the [[https://www.gnu.org/software/mit-scheme/documentation/mit-scheme-ref/Numerical-operations.html][MIT scheme manual]])

procedure: *quotient* n1 n2
procedure: *remainder* n1 n2
procedure: *modulo* n1 n2

These procedures implement number-theoretic (integer) division: for positive integers
n1 and n2, if n3 and n4 are integers such that then

#+BEGIN_SRC 
(quotient n1 n2)        ⇒  n3
(remainder n1 n2)       ⇒  n4
(modulo n1 n2)          ⇒  n4
#+END_SRC

For integers n1 and n2 with n2 not equal to 0,

#+BEGIN_SRC 
(= n1
   (+ (* n2 (quotient n1 n2))
      (remainder n1 n2)))
                                    ⇒  #t
#+END_SRC

provided all numbers involved in that computation are exact.

The value returned by quotient always has the sign of the product of its
arguments. remainder and modulo differ on negative arguments — the remainder always
has the sign of the dividend, the modulo always has the sign of the divisor:

#+BEGIN_SRC 
(modulo 13 4)           ⇒  1
(remainder 13 4)        ⇒  1

(modulo -13 4)          ⇒  3
(remainder -13 4)       ⇒  -1

(modulo 13 -4)          ⇒  -3
(remainder 13 -4)       ⇒  1

(modulo -13 -4)         ⇒  -1
(remainder -13 -4)      ⇒  -1

(remainder -13 -4.0)    ⇒  -1.0  ; inexact
#+END_SRC

Note that quotient is the same as integer-truncate.

*Identity*
#+BEGIN_EXAMPLE
GCD(a,b) = GCD(b,r)
#+END_EXAMPLE

Euclid's Algorithm for GCD
#+BEGIN_SRC scheme
(define (gcd a b)
  (if (= b 0)
      a
      (gcd b (remainder a b))))
#+END_SRC
in logarithmic time.

** Testing for Primality
Relies on if n is not prime it must have a divisor less than or equal to ~(sqrt n)~

#+BEGIN_SRC scheme
(define (prime? n)
  
  (define (smallest-divisor n)
    (find-divisor n 2))

  (define (find-divisor n test-divisor)
    (cond ((> (square test-divisor) n)
	   n)
	  ((divides? test-divisor n)
	   test-divisor)
	  (else
	   (find-divisor n (+ test-divisor 1)))))

  (define (divides? a b)
    (= (remainder b a) 0))

  (= n (smallest-divisor n)))
#+END_SRC

so time complexity of O(sqrt(n))

**** Fermat's Little Theorem
If /n/ is a prime number and /a/ is any positive integer less than /n/, then /a/ raised
to the /nth/ power is congruent to /a/ modulo /n/.

Most numbers ~a < n~ fail this test.
